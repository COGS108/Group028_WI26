{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rubric\n",
    "\n",
    "Instructions: DELETE this cell before you submit via a `git push` to your repo before deadline. This cell is for your reference only and is not needed in your report. \n",
    "\n",
    "Scoring: Out of 10 points\n",
    "\n",
    "- Each Developing  => -2 pts\n",
    "- Each Unsatisfactory/Missing => -4 pts\n",
    "  - until the score is \n",
    "\n",
    "If students address the detailed feedback in a future checkpoint they will earn these points back\n",
    "\n",
    "\n",
    "|                  | Unsatisfactory                                                                                                                                                                                                    | Developing                                                                                                                                                                                              | Proficient                                     | Excellent                                                                                                                              |\n",
    "|------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| Data relevance   | Did not have data relevant to their question. Or the datasets don't work together because there is no way to line them up against each other. If there are multiple datasets, most of them have this trouble | Data was only tangentially relevant to the question or a bad proxy for the question. If there are multiple datasets, some of them may be irrelevant or can't be easily combined.                       | All data sources are relevant to the question. | Multiple data sources for each aspect of the project. It's clear how the data supports the needs of the project.                         |\n",
    "| Data description | Dataset or its cleaning procedures are not described. If there are multiple datasets, most have this trouble                                                                                              | Data was not fully described. If there are multiple datasets, some of them are not fully described                                                                                                      | Data was fully described                       | The details of the data descriptions and perhaps some very basic EDA also make it clear how the data supports the needs of the project. |\n",
    "| Data wrangling   | Did not obtain data. They did not clean/tidy the data they obtained.  If there are multiple datasets, most have this trouble                                                                                 | Data was partially cleaned or tidied. Perhaps you struggled to verify that the data was clean because they did not present it well. If there are multiple datasets, some have this trouble | The data is cleaned and tidied.                | The data is spotless and they used tools to visualize the data cleanliness and you were convinced at first glance                      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Data Checkpoint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aaron Soekiatno: Conceptualization, Software, Visualization, Analysis\n",
    "Ezra Hong: Background research, Analysis, Data curation\n",
    "Dylan Dwight: Project administration, Experimental investigation, Writing - original draft\n",
    "Andrew Chon: Software, Methodology, Data curation\n",
    "Mai Tamura: Background research, Writing - original draft, Writing - review & editing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Question"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Research Question: Do Women's teams in the NCAA that win the first set have a significantly higher chance of winning a match that goes over 3 sets? And if they are the away team, is the match more competitive (smaller point differentials)?\n",
    "\n",
    "Metrics/Variables: Points, sets won and lost, point differentials, fans in attendance, and home or away court.\n",
    "\n",
    "Outcome: Match result (win/loss) \n",
    "Key predictor: First set result (win/loss) \n",
    "Additional variables: Second set result, set score margin, match format (best of 5)\n",
    "\n",
    "Analysis Type: We will calculate match win probabilities for teams based on whether they won or lost the first set. Using bar charts, pie charts, and conditional probability tables, we will visualize how first-set winners perform in the overall match. We will extend the analysis to see if the away team winning the first set leads to a more competitive match."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Match competitiveness is a key theme in volleyball analytics. Recent analytics has emphasized measurable indicators of competitiveness—such as point differentials, number of sets played, and home-court effects-to understand how closely intense matches turn out.\n",
    "\n",
    "Because matches are played as best-of-five sets in certain leagues, early outcomes do not guarantee final results, especially in matches extending beyond three sets. Research in collegiate athletics has also examined the role of home-court advantage in shaping competitive outcomes. Studies across NCAA sports have found that home teams benefit not only in win probability but also in scoring margins. In volleyball specifically, home advantage has been linked to factors such as crowd support, familiarity with the court conditions, and reduced traveling. However, less research has focused on how home or away status affects match competitiveness—particularly in matches that extend beyond three sets.\n",
    "\n",
    "Additionally, sports analytics literature increasingly uses point differential as a primary indicator of competitiveness. Smaller scoring margins across sets are widely interpreted as signals of evenly matched teams. Analyses in basketball, soccer, and volleyball have demonstrated that attendance and external factors can influence these margins, potentially increasing or decreasing competitive balance.\n",
    "\n",
    "Our project builds on this prior work by shifting the focus to strictly competitiveness and results of matches that extend to 3 sets. Specifically, we examine whether winning the first set meaningfully predicts match outcomes in extended matches, and whether away teams that win the first set experience more competitive matches, as measured by smaller point differentials when compared to home teams. By concentrating on measurable indicators of competitive intensity, our project aims to provide a clearer understanding of how early advantages shape the competitiveness of NCAA women’s volleyball matches, especially if they are an away team."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hypothesis: Among the 2019 NCAA women's volleyball dataset for matches that extend past 3 sets, the team that won the first set will only have a slightly higher chance to win the match. Additionally, when the away team wins the first set, the match will have a smaller overall point differential, indicating greater competitiveness.\n",
    "\n",
    "Reasoning: Winning the first set as the away team will likely increase competitiveness and pressure on the opposing team. Additionally, the team that wins the first set has demonstrated early that they can outperform their opponent, which may reflect a  skill advantage that carries through the rest of the match."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset #1\n",
    "- NCAA Division I Women's Volleyball 2019 Match Results\n",
    "- Link: https://github.com/larget/stat-240-case-studies/blob/master/data/vb-division1-2019-all-matches.csv\n",
    "- Number of observations: 4,958 matches (one row per match minus initial row).\n",
    "- Number of variables: 19 (columns).\n",
    "- Description of variables: The variables most relevant to this project include; team1/team2 (the two teams competing in the match), site (location of the match, indicates home, away, neutral), s1_1 to s1_5 (points scored by Team 1 in sets 1-5), s2_1 to s2_5 (points scored by Team 2 in sets 1-5), sets_1 (total amount of sets won by Team 1), sets_2 (total amount of sets won by Team 2), winner (team that won the match), loser (team that lost the match), and attendance (total match attendance).\n",
    "- Description of shortcomings: The data set only includes the 2019 season, the data set does not have a specific match competitiveness variable, some of the rows have missing data in attendance and the site, teams appear multiple times in different matches (observations are not fully independent), and it lacks factors like team rankings, strength, conference differences, or postseason status, which could influence both first set outcomes and overall match competitiveness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code every time when you're actively developing modules in .py files.  It's not needed if you aren't making modules\n",
    "#\n",
    "## this code is necessary for making sure that any modules we load are updated here \n",
    "## when their source code .py files are modified\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall Download Progress:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Downloading vball_matches.csv:   0%|          | 0.00/99.8k [00:00<?, ?B/s]\u001b[A\n",
      "Overall Download Progress: 100%|██████████| 1/1 [00:00<00:00,  5.35it/s]  \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded: vball_matches.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Setup code -- this only needs to be run once after cloning the repo!\n",
    "# this code downloads the data from its source to the `data/00-raw/` directory\n",
    "# if the data hasn't updated you don't need to do this again!\n",
    "\n",
    "# if you don't already have these packages (you should!) uncomment this line\n",
    "# %pip install requests tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append('./modules') # this tells python where to look for modules to import\n",
    "\n",
    "import get_data # this is where we get the function we need to download data\n",
    "\n",
    "# replace the urls and filenames in this list with your actual datafiles\n",
    "# yes you can use Google drive share links or whatever\n",
    "# format is a list of dictionaries; \n",
    "# each dict has keys of \n",
    "#   'url' where the resource is located\n",
    "#   'filename' for the local filename where it will be stored \n",
    "datafiles = [\n",
    "    { 'url': 'https://raw.githubusercontent.com/larget/stat-240-case-studies/refs/heads/master/data/vb-division1-2019-all-matches.csv', 'filename':'vball_matches.csv'}\n",
    "]\n",
    "\n",
    "get_data.get_raw(datafiles,destination_directory='data/00-raw/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Women's NCAA Volleyball Matches Dataset #1\n",
    "\n",
    "Instructions: \n",
    "1. Change the header from Dataset #1 to something more descriptive of the dataset\n",
    "2. Write a few paragraphs about this dataset. Make sure to cover\n",
    "   1. Describe the important metrics, what units they are in, and giv some sense of what they mean.  For example \"Fasting blood glucose in units of mg glucose per deciliter of blood.  Normal values for healthy individuals range from 70 to 100 mg/dL.  Values 100-125 are prediabetic and values >125mg/dL indicate diabetes. Values <70 indicate hypoglycemia. Fasting idicates the patient hasn't eaten in the last 8 hours.  If blood glucose is >250 or <50 at any time (regardless of the time of last meal) the patient's life may be in immediate danger\"\n",
    "   2. If there are any major concerns with the dataset, describe them. For example \"Dataset is composed of people who are serious enough about eating healthy that they voluntarily downloaded an app dedicated to tracking their eating patterns. This sample is likely biased because of that self-selection. These people own smartphones and may be healthier and may have more disposable income than the average person.  Those who voluntarily log conscientiously and for long amounts of time are also likely even more interested in health than those who download the app and only log a bit before getting tired of it\"\n",
    "3. Use the cell below to \n",
    "    1. load the dataset \n",
    "    2. make the dataset tidy or demonstrate that it was already tidy\n",
    "    3. demonstrate the size of the dataset\n",
    "    4. find out how much data is missing, where its missing, and if its missing at random or seems to have any systematic relationships in its missingness\n",
    "    5. find and flag any outliers or suspicious entries\n",
    "    6. clean the data or demonstrate that it was already clean.  You may choose how to deal with missingness (dropna of fillna... how='any' or 'all') and you should justify your choice in some way\n",
    "    7. You will load raw data from `data/00-raw/`, you will (optionally) write intermediate stages of your work to `data/01-interim` and you will write the final fully wrangled version of your data to `data/02-processed`\n",
    "4. Optionally you can also show some summary statistics for variables that you think are important to the project\n",
    "5. Feel free to add more cells here if that's helpful for you\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.\n",
    "    This dataset contains match data from NCAA Division I women’s volleyball, where each row represents a single match and includes scoring results, sets won & lost, home/away, and fan attendance. Points are recorded per set, and total point differential across a match serves as a measure of competitiveness, with smaller point differentials showing more competitive matches. Because teams must win three sets to win a match, matches that go to four or five sets generally show higher competitiveness than three-set matches, while attendance (number of fans) and the site shows context for potential home-court effects.\n",
    "    The data set only includes the 2019 season, which may show bias. It also doesn't have a specific match competitiveness variable, which we will have to compute on our own through the point and set differentials. Some of the rows have missing data in the attendance and the site location, which may cause problems in the amount of data we have to analyze. Some teams appear multiple times in different matches, showing that observations are not fully independent, and team factors like rankings, strength, and postseason status are missing, which are factors that may affect match competitiveness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>team1</th>\n",
       "      <th>team2</th>\n",
       "      <th>site</th>\n",
       "      <th>s1_1</th>\n",
       "      <th>s1_2</th>\n",
       "      <th>s1_3</th>\n",
       "      <th>s1_4</th>\n",
       "      <th>s1_5</th>\n",
       "      <th>sets_1</th>\n",
       "      <th>s2_1</th>\n",
       "      <th>s2_2</th>\n",
       "      <th>s2_3</th>\n",
       "      <th>s2_4</th>\n",
       "      <th>s2_5</th>\n",
       "      <th>sets_2</th>\n",
       "      <th>winner</th>\n",
       "      <th>loser</th>\n",
       "      <th>attendance</th>\n",
       "      <th>total_sets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-08-30</td>\n",
       "      <td>South Carolina St.</td>\n",
       "      <td>Texas Southern</td>\n",
       "      <td>@Montgomery, Ala.</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2</td>\n",
       "      <td>21.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Texas Southern</td>\n",
       "      <td>South Carolina St.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-08-30</td>\n",
       "      <td>SIUE</td>\n",
       "      <td>UC Riverside</td>\n",
       "      <td>@DeKalb, IL</td>\n",
       "      <td>17.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>UC Riverside</td>\n",
       "      <td>SIUE</td>\n",
       "      <td>75.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-08-30</td>\n",
       "      <td>Temple</td>\n",
       "      <td>Fairfield</td>\n",
       "      <td>@Baltimore, MD</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Temple</td>\n",
       "      <td>Fairfield</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-08-30</td>\n",
       "      <td>Niagara</td>\n",
       "      <td>Stetson</td>\n",
       "      <td>@Boca Raton, FL</td>\n",
       "      <td>17.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Stetson</td>\n",
       "      <td>Niagara</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019-08-30</td>\n",
       "      <td>Howard</td>\n",
       "      <td>Hartford</td>\n",
       "      <td>@Washington, DC</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Howard</td>\n",
       "      <td>Hartford</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date               team1           team2               site  s1_1  \\\n",
       "1  2019-08-30  South Carolina St.  Texas Southern  @Montgomery, Ala.  25.0   \n",
       "3  2019-08-30                SIUE    UC Riverside        @DeKalb, IL  17.0   \n",
       "4  2019-08-30              Temple       Fairfield     @Baltimore, MD  25.0   \n",
       "6  2019-08-30             Niagara         Stetson    @Boca Raton, FL  17.0   \n",
       "7  2019-08-30              Howard        Hartford    @Washington, DC  25.0   \n",
       "\n",
       "   s1_2  s1_3  s1_4  s1_5  sets_1  s2_1  s2_2  s2_3  s2_4  s2_5  sets_2  \\\n",
       "1  25.0  12.0  18.0  17.0       2  21.0  20.0  25.0  25.0  19.0       3   \n",
       "3  20.0  18.0   NaN   NaN       0  25.0  25.0  25.0   NaN   NaN       3   \n",
       "4  25.0  25.0   NaN   NaN       3  20.0  15.0  13.0   NaN   NaN       0   \n",
       "6  14.0  16.0   NaN   NaN       0  25.0  25.0  25.0   NaN   NaN       3   \n",
       "7  25.0  25.0   NaN   NaN       3  23.0  23.0  20.0   NaN   NaN       0   \n",
       "\n",
       "           winner               loser  attendance  total_sets  \n",
       "1  Texas Southern  South Carolina St.         0.0           5  \n",
       "3    UC Riverside                SIUE        75.0           3  \n",
       "4          Temple           Fairfield         0.0           3  \n",
       "6         Stetson             Niagara         0.0           3  \n",
       "7          Howard            Hartford         0.0           3  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## YOUR CODE TO LOAD/CLEAN/TIDY/WRANGLE THE DATA GOES HERE\n",
    "import pandas as pd\n",
    "df = pd.read_csv('data/00-raw/vball_matches.csv')\n",
    "df = df.dropna(subset=['site'])\n",
    "df['total_sets'] = df['sets_1'] + df['sets_2']\n",
    "df_competitive = df[df['total_sets'] >= 4]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(531, 20)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_competitive.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset #2 \n",
    "\n",
    "See instructions above for Dataset #1.  Feel free to keep adding as many more datasets as you need.  Put each new dataset in its own section just like these. \n",
    "\n",
    "Lastly if you do have multiple datasets, add another section where you demonstrate how you will join, align, cross-reference or whatever to combine data from the different datasets\n",
    "\n",
    "Please note that you can always keep adding more datasets in the future if these datasets you turn in for the checkpoint aren't sufficient.  The goal here is demonstrate that you can obtain and wrangle data.  You are not tied down to only use what you turn in right now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE TO LOAD/CLEAN/TIDY/WRANGLE THE DATA GOES HERE\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ethics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A. Data Collection\n",
    "A.1 Informed consent: If there are human subjects, have they given informed consent, where subjects affirmatively opt-in and have a clear understanding of the data uses to which they consent?\n",
    "A.2 Collection bias: Have we considered sources of bias that could be introduced during data collection and survey design and taken steps to mitigate those?\n",
    "A.3 Limit PII exposure: Have we considered ways to minimize exposure of personally identifiable information (PII) for example through anonymization or not collecting information that isn't relevant for analysis?\n",
    "A.4 Downstream bias mitigation: Have we considered ways to enable testing downstream results for biased outcomes (e.g., collecting data on protected group status like race or gender)?\n",
    "B. Data Storage\n",
    "B.1 Data security: Do we have a plan to protect and secure data (e.g., encryption at rest and in transit, access controls on internal users and third parties, access logs, and up-to-date software)?\n",
    "B.2 Right to be forgotten: Do we have a mechanism through which an individual can request their personal information be removed?\n",
    "B.3 Data retention plan: Is there a schedule or plan to delete the data after it is no longer needed?\n",
    "C. Analysis\n",
    "C.1 Missing perspectives: Have we sought to address blindspots in the analysis through engagement with relevant stakeholders (e.g., checking assumptions and discussing implications with affected communities and subject matter experts)?\n",
    "C.2 Dataset bias: Have we examined the data for possible sources of bias and taken steps to mitigate or address these biases (e.g., stereotype perpetuation, confirmation bias, imbalanced classes, or omitted confounding variables)?\n",
    "C.3 Honest representation: Are our visualizations, summary statistics, and reports designed to honestly represent the underlying data?\n",
    "C.4 Privacy in analysis: Have we ensured that data with PII are not used or displayed unless necessary for the analysis?\n",
    "C.5 Auditability: Is the process of generating the analysis well documented and reproducible if we discover issues in the future?\n",
    "D. Modeling\n",
    "D.1 Proxy discrimination: Have we ensured that the model does not rely on variables or proxies for variables that are unfairly discriminatory?\n",
    "D.2 Fairness across groups: Have we tested model results for fairness with respect to different affected groups (e.g., tested for disparate error rates)?\n",
    "D.3 Metric selection: Have we considered the effects of optimizing for our defined metrics and considered additional metrics?\n",
    "D.4 Explainability: Can we explain in understandable terms a decision the model made in cases where a justification is needed?\n",
    "D.5 Communicate limitations: Have we communicated the shortcomings, limitations, and biases of the model to relevant stakeholders in ways that can be generally understood?\n",
    "E. Deployment\n",
    "E.1 Monitoring and evaluation: Do we have a clear plan to monitor the model and its impacts after it is deployed (e.g., performance monitoring, regular audit of sample predictions, human review of high-stakes decisions, reviewing downstream impacts of errors or low-confidence decisions, testing for concept drift)?\n",
    "E.2 Redress: Have we discussed with our organization a plan for response if users are harmed by the results (e.g., how does the data science team evaluate these cases and update analysis and models to prevent future harm)?\n",
    "E.3 Roll back: Is there a way to turn off or roll back the model in production if necessary?\n",
    "E.4 Unintended use: Have we taken steps to identify and prevent unintended uses and abuse of the model and do we have a plan to monitor these once the model is deployed?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Expectations "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Team Expectation 1 For communication, we will mainly use Instagram, and we expect response times to be around 24 hours.\n",
    "\n",
    "Team Expectation 2 We expect to provide and receive polite feedback from our group members.\n",
    "\n",
    "Team Expectation 3 We divided up tasks evenly throughout the proposal, but it is subject to change as we work on the project.\n",
    "\n",
    "Team Expectation 4 If anyone is falling behind and or can't meet a certain deadline, we all agreed that they need to notify the group at least a day before."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Timeline Proposal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROJECT MEETING TIMELINE\n",
    "\n",
    "------------------------------------------------------------\n",
    "Date: January 20\n",
    "Time: 1:00 PM\n",
    "Completed Before Meeting:\n",
    "- Read and reflect on COGS 108 expectations\n",
    "- Brainstorm potential project topics and research questions\n",
    "\n",
    "Discuss at Meeting:\n",
    "- Determine primary form of group communication\n",
    "------------------------------------------------------------\n",
    "\n",
    "Date: February 4\n",
    "Time: 5:00 PM\n",
    "Completed Before Meeting:\n",
    "- Decide on final project topic\n",
    "- Develop hypothesis\n",
    "- Begin background research\n",
    "- Discuss ideal datasets and ethical considerations\n",
    "- Complete project proposal\n",
    "\n",
    "Discuss at Meeting:\n",
    "- Finalize and submit proposal\n",
    "------------------------------------------------------------\n",
    "\n",
    "Date: February 11\n",
    "Time: 10:00 AM\n",
    "Completed Before Meeting:\n",
    "- Search for relevant datasets\n",
    "\n",
    "Discuss at Meeting:\n",
    "- Discuss data wrangling strategy\n",
    "- Identify possible analytical approaches\n",
    "------------------------------------------------------------\n",
    "\n",
    "Date: February 14\n",
    "Time: 6:00 PM\n",
    "Completed Before Meeting:\n",
    "- Import and wrangle data\n",
    "- Conduct initial exploratory data analysis (EDA)\n",
    "\n",
    "Discuss at Meeting:\n",
    "- Review and edit wrangling/EDA\n",
    "- Refine analysis plan\n",
    "------------------------------------------------------------\n",
    "\n",
    "Date: February 23\n",
    "Time: 12:00 PM\n",
    "Completed Before Meeting:\n",
    "- Finalize wrangling and EDA\n",
    "- Begin formal analysis\n",
    "\n",
    "Discuss at Meeting:\n",
    "- Review and edit analysis\n",
    "- Complete project check-in\n",
    "------------------------------------------------------------\n",
    "\n",
    "Date: March 13\n",
    "Time: 12:00 PM\n",
    "Completed Before Meeting:\n",
    "- Complete analysis\n",
    "- Draft results, conclusion, and discussion\n",
    "\n",
    "Discuss at Meeting:\n",
    "- Review and edit full project draft\n",
    "------------------------------------------------------------\n",
    "\n",
    "Date: March 20\n",
    "Time: Before 11:59 PM\n",
    "Completed Before Meeting:\n",
    "- N/A\n",
    "\n",
    "Discuss at Meeting:\n",
    "- Submit final project\n",
    "- Complete group project surveys\n",
    "------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "16b860a9f5fc21240e9d88c0ee13691518c3ce67be252e54a03b9b5b11bd3c7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
